{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3ecd738b-59d5-4e8e-a113-0fb1f9b82dd7",
      "metadata": {
        "id": "3ecd738b-59d5-4e8e-a113-0fb1f9b82dd7"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2d5b901c-2c71-4649-b6dc-9a6ab3176c40",
      "metadata": {
        "id": "2d5b901c-2c71-4649-b6dc-9a6ab3176c40"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(\"data (1).zip\", 'r') as zObject:\n",
        "    zObject.extractall(path=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6343aa32-9b04-4632-a18b-c45d28d385fb",
      "metadata": {
        "id": "6343aa32-9b04-4632-a18b-c45d28d385fb"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0:\"SOS\", 1:\"EOS\"}\n",
        "    self.n_words = 2\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b2f75c47-be71-4cbf-a812-eed583461065",
      "metadata": {
        "id": "b2f75c47-be71-4cbf-a812-eed583461065"
      },
      "outputs": [],
      "source": [
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "  )\n",
        "\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "  return s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "472513d5-3af4-47eb-ab69-7cc0f883eed5",
      "metadata": {
        "id": "472513d5-3af4-47eb-ab69-7cc0f883eed5"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "  print(\"Reading Lines......\")\n",
        "\n",
        "  lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "  if reverse:\n",
        "    pairs = [list(reversed(p)) for p in pairs]\n",
        "    input_lang = Lang(lang2)\n",
        "    output_lang = Lang(lang1)\n",
        "  else:\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "\n",
        "  return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "58d1d021-6118-44ce-b447-5bcdc8abc0db",
      "metadata": {
        "id": "58d1d021-6118-44ce-b447-5bcdc8abc0db"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "  return len(p[0].split(' ')) < MAX_LEN and len(p[1].split(' ')) < MAX_LEN and p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "  return [p for p in pairs if filterPair(p)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "091d638c-7363-4b2f-85f0-e29e66f37f63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "091d638c-7363-4b2f-85f0-e29e66f37f63",
        "outputId": "70cd41f5-d56b-4bb2-fe8d-fc5bf2a3ae63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Lines......\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words....\n",
            "Counted Words\n",
            "fra 4601\n",
            "eng 2991\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse = False):\n",
        "  input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "  print(\"Read %s sentence pairs\" %len(pairs))\n",
        "  pairs = filterPairs(pairs)\n",
        "  print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "  print(\"Counting words....\")\n",
        "  for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "  print(\"Counted Words\")\n",
        "  print(input_lang.name, input_lang.n_words)\n",
        "  print(output_lang.name, output_lang.n_words)\n",
        "  return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng','fra',True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "52b37c37-e984-4f4c-9688-f8208e2dbdbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52b37c37-e984-4f4c-9688-f8208e2dbdbc",
        "outputId": "9ca3bc9e-8b9a-43bd-ec69-ae0150087efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nous avons l intention de gravir cette montagne', 'we are going to climb that mountain']\n"
          ]
        }
      ],
      "source": [
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5717ae85-8018-4485-88ab-2a4ec269c61a",
      "metadata": {
        "id": "5717ae85-8018-4485-88ab-2a4ec269c61a"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self, input):\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    # print('embedded :', embedded.shape)\n",
        "    output, hidden = self.gru(embedded)\n",
        "    # print('output :', output.shape)\n",
        "    # print('Hidden :', hidden[0].shape)\n",
        "    return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "576432b8-8e71-49e5-b0fb-ed4559dd3f8d",
      "metadata": {
        "id": "576432b8-8e71-49e5-b0fb-ed4559dd3f8d"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LEN):\n",
        "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "10462944-9368-4c73-b6fa-7a80cbc2623e",
      "metadata": {
        "id": "10462944-9368-4c73-b6fa-7a80cbc2623e"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "  return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "  indexes = indexesFromSentence(lang, sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=device).view(1,-1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "  target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "  input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "\n",
        "  n = len(pairs)\n",
        "  input_ids = np.zeros((n,MAX_LEN), dtype=np.int32)\n",
        "  target_ids = np.zeros((n,MAX_LEN), dtype=np.int32)\n",
        "\n",
        "  for idx, (inp, tgt) in enumerate(pairs):\n",
        "    inp_ids = indexesFromSentence(input_lang, inp)\n",
        "    tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "    inp_ids.append(EOS_token)\n",
        "    tgt_ids.append(EOS_token)\n",
        "    input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "    target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "  train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                             torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "  return input_lang, output_lang, train_dataloader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c64ffdd6-2efa-4c10-8866-4a0b1f8fa37a",
      "metadata": {
        "id": "c64ffdd6-2efa-4c10-8866-4a0b1f8fa37a"
      },
      "outputs": [],
      "source": [
        "def train_epoch(data_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "\n",
        "  total_loss = 0\n",
        "  for data in data_loader:\n",
        "    input_tensor, target_tensor = data\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "    decoder_outputs,_,_ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "    loss = criterion(\n",
        "        decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "        target_tensor.view(-1)\n",
        "    )\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "  return total_loss / len(data_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2e32e189-bfda-485f-ba7d-a56d235dde55",
      "metadata": {
        "id": "2e32e189-bfda-485f-ba7d-a56d235dde55"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0589f425-0ab5-45e7-a4a3-0a42538e3b82",
      "metadata": {
        "id": "0589f425-0ab5-45e7-a4a3-0a42538e3b82"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, print_every=100, plot_every=100):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0\n",
        "  plot_loss_total = 0\n",
        "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    print_loss_total += loss\n",
        "    if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b37214fe-61b1-4d29-b82d-cbe7ccb8bfde",
      "metadata": {
        "id": "b37214fe-61b1-4d29-b82d-cbe7ccb8bfde"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "    encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "\n",
        "    decoder_outputs, decoder_hidden, decoder_attention = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "    _, topi = decoder_outputs.topk(1)\n",
        "    decoded_ids = topi.squeeze()\n",
        "    decoded_words = []\n",
        "\n",
        "    for idx in decoded_ids:\n",
        "      if idx.item()==EOS_token:\n",
        "        decoded_words.append('<EOS>')\n",
        "        break\n",
        "      else:\n",
        "        decoded_words.append(output_lang.index2word[idx.item()])\n",
        "  return decoded_words, decoder_attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c0d52fa1-8985-4302-95a7-448886fd3a68",
      "metadata": {
        "id": "c0d52fa1-8985-4302-95a7-448886fd3a68"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fe81cc01-0b1d-46e8-8cc3-1b81df536fa1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe81cc01-0b1d-46e8-8cc3-1b81df536fa1",
        "outputId": "104c7024-af98-459a-a9d8-15c33172a892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Lines......\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words....\n",
            "Counted Words\n",
            "fra 4601\n",
            "eng 2991\n",
            "0m 20s (- 5m 9s) (5 6%) 1.6970\n",
            "0m 39s (- 4m 35s) (10 12%) 0.9124\n",
            "0m 57s (- 4m 8s) (15 18%) 0.5884\n",
            "1m 16s (- 3m 49s) (20 25%) 0.4014\n",
            "1m 34s (- 3m 27s) (25 31%) 0.2839\n",
            "1m 53s (- 3m 8s) (30 37%) 0.2071\n",
            "2m 11s (- 2m 48s) (35 43%) 0.1564\n",
            "2m 30s (- 2m 30s) (40 50%) 0.1208\n",
            "2m 48s (- 2m 10s) (45 56%) 0.0969\n",
            "3m 6s (- 1m 52s) (50 62%) 0.0795\n",
            "3m 25s (- 1m 33s) (55 68%) 0.0673\n",
            "3m 43s (- 1m 14s) (60 75%) 0.0585\n",
            "4m 2s (- 0m 55s) (65 81%) 0.0521\n",
            "4m 20s (- 0m 37s) (70 87%) 0.0473\n",
            "4m 39s (- 0m 18s) (75 93%) 0.0433\n",
            "4m 57s (- 0m 0s) (80 100%) 0.0413\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "176cdfb7-8d0c-42af-9786-68de2825f1bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "176cdfb7-8d0c-42af-9786-68de2825f1bb",
        "outputId": "0942c3c2-3cfc-43de-b113-d07069b622ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> vous etes fort braves\n",
            "= you re very brave\n",
            "< you re confused again aren t you ? <EOS>\n",
            "\n",
            "> je suis pret a mourir\n",
            "= i am ready to die\n",
            "< i am ready to go to boston on sundays <EOS>\n",
            "\n",
            "> il est trop jeune pour y aller seul\n",
            "= he is too young to go there alone\n",
            "< he is too young to go there alone <EOS>\n",
            "\n",
            "> elles sont juste derriere vous\n",
            "= they re right behind you\n",
            "< they re right behind you <EOS>\n",
            "\n",
            "> je pars ce soir\n",
            "= i m departing this evening\n",
            "< i m leaving tonight for australia <EOS>\n",
            "\n",
            "> je suis en train d engager des poursuites\n",
            "= i m pressing charges\n",
            "< i m pressing charges <EOS>\n",
            "\n",
            "> il est responsable de cet accident\n",
            "= he is responsible for the accident\n",
            "< he is responsible for the accident <EOS>\n",
            "\n",
            "> c est un ami de mon frere\n",
            "= he s a friend of my brother s\n",
            "< he is a wolf in sheep s clothing <EOS>\n",
            "\n",
            "> je te le demande en tant qu ami\n",
            "= i m asking you as a friend\n",
            "< i m asking you as a friend <EOS>\n",
            "\n",
            "> je ne suis toujours pas sure\n",
            "= i m still not sure\n",
            "< i m still not sure i want to see <EOS>\n",
            "\n",
            "> j ai froid\n",
            "= i am cold\n",
            "< i am being paid to do the job <EOS>\n",
            "\n",
            "> vous etes tres grossiere\n",
            "= you re very rude\n",
            "< you re very rude to me <EOS>\n",
            "\n",
            "> j en suis familier\n",
            "= i m accustomed to this\n",
            "< i m ready to be back on business <EOS>\n",
            "\n",
            "> je vais avoir trente ans en octobre\n",
            "= i m turning thirty in october\n",
            "< i m turning thirty in the park <EOS>\n",
            "\n",
            "> nous perdons tous du temps\n",
            "= we re all wasting time\n",
            "< we re all wasting time <EOS>\n",
            "\n",
            "> vous etes tres vive\n",
            "= you re very sharp\n",
            "< you re very religious not this <EOS>\n",
            "\n",
            "> je suis plus qu heureuse\n",
            "= i m more than happy\n",
            "< i m more than just a pretty face <EOS>\n",
            "\n",
            "> je suis ravi que vous ayez pu le faire\n",
            "= i m glad you could make it\n",
            "< i m glad you could make it <EOS>\n",
            "\n",
            "> vous n etes pas des notres si ?\n",
            "= you re not one of us are you ?\n",
            "< you re not one of us are you ? <EOS>\n",
            "\n",
            "> nous sommes canadiennes\n",
            "= we re canadians\n",
            "< we re busy things <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder, decoder, 20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1CcU5S3spcr",
        "outputId": "d068c898-f27e-4d70-f428-d6d89f02227c"
      },
      "id": "a1CcU5S3spcr",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a25b675a-5e56-49a1-824b-bb516c94eeb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a25b675a-5e56-49a1-824b-bb516c94eeb6",
        "outputId": "e3570030-e9b3-4428-b510-daf50cc5ccd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.28764198060873264\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def calculate_bleu(reference, candidate):\n",
        "    reference = [word_tokenize(sentence.lower()) for sentence in reference]\n",
        "    candidate = word_tokenize(candidate.lower())\n",
        "\n",
        "    smoothing_function = SmoothingFunction().method1  # You can choose different smoothing methods\n",
        "\n",
        "    return sentence_bleu(reference, candidate, smoothing_function=smoothing_function)\n",
        "\n",
        "# Example usage:\n",
        "reference_sentence = [\"The cat is sitting on the mat\"]\n",
        "candidate_sentence = \"The cat is on the mat\"\n",
        "\n",
        "bleu_score = calculate_bleu(reference_sentence, candidate_sentence)\n",
        "print(f\"BLEU Score: {bleu_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "cc72d22f-88b0-4c6a-8db7-5581f6c1cef6",
      "metadata": {
        "id": "cc72d22f-88b0-4c6a-8db7-5581f6c1cef6"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def bleu_metric(encoder, decoder, n=10):\n",
        "    bleu=0\n",
        "    for i in tqdm(range(n)):\n",
        "        pair = random.choice(pairs)\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        reference_sentence = [pair[1]]\n",
        "        candidate_sentence = output_sentence\n",
        "        bleu+= calculate_bleu(reference_sentence, candidate_sentence)\n",
        "    return bleu/n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b19624c4-e8c2-43c9-b308-1c12de55d6b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b19624c4-e8c2-43c9-b308-1c12de55d6b2",
        "outputId": "6b1dc876-80b8-49bb-b333-b35f48cfdda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:42<00:00, 235.50it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28478144156513185"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "bleu_metric(encoder, decoder, n=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2b7a96-d754-479c-811f-07c509cfc55d",
      "metadata": {
        "id": "eb2b7a96-d754-479c-811f-07c509cfc55d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env1",
      "language": "python",
      "name": "env1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}