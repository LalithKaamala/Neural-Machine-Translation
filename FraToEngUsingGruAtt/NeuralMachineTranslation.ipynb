{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EZg7sHZh7fAD"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MwcEkPpA7j2o"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"data (1).zip\", 'r') as zObject:\n",
    "    zObject.extractall(path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A2dHKMKm8AMS"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.word2index = {}\n",
    "    self.word2count = {}\n",
    "    self.index2word = {0:\"SOS\", 1:\"EOS\"}\n",
    "    self.n_words = 2\n",
    "  def addSentence(self, sentence):\n",
    "    for word in sentence.split(' '):\n",
    "      self.addWord(word)\n",
    "  def addWord(self, word):\n",
    "    if word not in self.word2index:\n",
    "      self.word2index[word] = self.n_words\n",
    "      self.word2count[word] = 1\n",
    "      self.index2word[self.n_words] = word\n",
    "      self.n_words += 1\n",
    "    else:\n",
    "      self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v-TYWyLI9vUj"
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "  return ''.join(\n",
    "      c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn'\n",
    "  )\n",
    "\n",
    "def normalizeString(s):\n",
    "  s = unicodeToAscii(s.lower().strip())\n",
    "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "  s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "  return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Zk9gnnox-LzA"
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "  print(\"Reading Lines......\")\n",
    "\n",
    "  lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "  if reverse:\n",
    "    pairs = [list(reversed(p)) for p in pairs]\n",
    "    input_lang = Lang(lang2)\n",
    "    output_lang = Lang(lang1)\n",
    "  else:\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "  return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FUf5p6Dh_xPR"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "  return len(p[0].split(' ')) < MAX_LEN and len(p[1].split(' ')) < MAX_LEN and p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "  return [p for p in pairs if filterPair(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8bJ-FR9G5VA",
    "outputId": "a8b98ece-829f-4077-ded7-30dbf73ce10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Lines......\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words....\n",
      "Counted Words\n",
      "fra 4601\n",
      "eng 2991\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse = False):\n",
    "  input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "  print(\"Read %s sentence pairs\" %len(pairs))\n",
    "  pairs = filterPairs(pairs)\n",
    "  print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "  print(\"Counting words....\")\n",
    "  for pair in pairs:\n",
    "    input_lang.addSentence(pair[0])\n",
    "    output_lang.addSentence(pair[1])\n",
    "  print(\"Counted Words\")\n",
    "  print(input_lang.name, input_lang.n_words)\n",
    "  print(output_lang.name, output_lang.n_words)\n",
    "  return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng','fra',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOw1kLlcH462",
    "outputId": "0d4f0ea6-aeaa-4fca-d67f-02b095872a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vous etes fantasque', 'you re temperamental']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XXWnxwLRIAqA"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "    super(EncoderRNN, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "    self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "  def forward(self, input):\n",
    "    embedded = self.dropout(self.embedding(input))\n",
    "    # print('embedded :', embedded.shape)\n",
    "    output, hidden = self.gru(embedded)\n",
    "    # print('output :', output.shape)\n",
    "    # print('Hidden :', hidden[0].shape)\n",
    "    return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ko1DAxupMVH2"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "  def __init__(self, hidden_size):\n",
    "    super(BahdanauAttention,self).__init__()\n",
    "    self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "    self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "    self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "  def forward(self, query, keys):\n",
    "    # print(self.Wa(query).shape)\n",
    "    # print(self.Ua(keys).shape)\n",
    "    scores = self.Va(torch.tanh( self.Wa(query) + self.Ua(keys) ))\n",
    "    # print('Scores :', scores.shape)\n",
    "    scores = scores.squeeze(2).unsqueeze(1)\n",
    "    # print('Scores :', scores.shape)\n",
    "\n",
    "    weights = F.softmax(scores, dim = -1)\n",
    "    # print('Weights : ', weights.shape)\n",
    "    context = torch.bmm(weights, keys)\n",
    "    # print('context : ', context.shape)\n",
    "    return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "p3zHlFYaOBH2"
   },
   "outputs": [],
   "source": [
    "# att = BahdanauAttention(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AOPhdY6BOHN7"
   },
   "outputs": [],
   "source": [
    "# query = torch.randn((32, 1 ,128))\n",
    "# keys = torch.randn((32, 10, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6nQfa7NrOAN_"
   },
   "outputs": [],
   "source": [
    "# context, weights = att.forward(query, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9KhlRxfTOWz5"
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "  def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "    super(AttnDecoderRNN, self).__init__()\n",
    "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "    self.attention = BahdanauAttention(hidden_size)\n",
    "    self.gru = nn.GRU(2*hidden_size, hidden_size, batch_first=True)\n",
    "    self.out = nn.Linear(hidden_size, output_size)\n",
    "    self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "  def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "    batch_size = encoder_outputs.size(0)\n",
    "    decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "    # print('initial_decoder_inp : ', decoder_input.shape)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # print('decoder_hidden:', decoder_hidden.shape)\n",
    "    decoder_outputs = []\n",
    "    attentions = []\n",
    "    for i in range(MAX_LEN):\n",
    "      decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "          decoder_input, decoder_hidden, encoder_outputs\n",
    "      )\n",
    "      decoder_outputs.append(decoder_output)\n",
    "      attentions.append(attn_weights)\n",
    "\n",
    "      if target_tensor is not None:\n",
    "        decoder_input = target_tensor[:,i].unsqueeze(1)\n",
    "\n",
    "      else:\n",
    "        _, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze(-1).detach()\n",
    "\n",
    "    decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "    decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "    attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "    return decoder_outputs, decoder_hidden, attentions\n",
    "  def forward_step(self, inp, hidden, encoder_outputs):\n",
    "    # print('inp : ', inp.shape)\n",
    "    embedded = self.dropout(self.embedding(inp))\n",
    "    # print('hidden : ', hidden.shape)\n",
    "    query = hidden.permute(1,0,2)\n",
    "    # print('query : ', query.shape)\n",
    "    # print('enc_out : ', encoder_outputs.shape)\n",
    "    context, attn_weights = self.attention(query, encoder_outputs)\n",
    "    input_gru = torch.cat((embedded, context), dim=2)\n",
    "    # print('input_gru :', input_gru.shape)\n",
    "    output, hidden  = self.gru(input_gru, hidden)\n",
    "    output = self.out(output)\n",
    "\n",
    "    return output, hidden, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cDqypEjfS6fN"
   },
   "outputs": [],
   "source": [
    "enc = EncoderRNN(input_lang.n_words, hidden_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "57RpDVHRS8qp"
   },
   "outputs": [],
   "source": [
    "rand_inp = torch.randint(1, input_lang.n_words, size=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBxlqtypS-XL",
    "outputId": "cd131c7c-008b-4a81-9b52-5570544d2ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded : torch.Size([32, 10, 128])\n",
      "output : torch.Size([32, 10, 128])\n",
      "Hidden : torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "output, hidden = enc.forward(rand_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "luFKC0FPSpSc"
   },
   "outputs": [],
   "source": [
    "# dec = AttnDecoderRNN(128, output_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "170o6zhTTHKJ"
   },
   "outputs": [],
   "source": [
    "# ran_tar = torch.randint(1, output_lang.n_words, size=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GBR6rZLRSwNJ"
   },
   "outputs": [],
   "source": [
    "# out, hid, att = dec.forward(output, hidden, ran_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Uq78n3jDTExV"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "  return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "  indexes = indexesFromSentence(lang, sentence)\n",
    "  indexes.append(EOS_token)\n",
    "  return torch.tensor(indexes, dtype=torch.long, device=device).view(1,-1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "  target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "  return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "  input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "\n",
    "  n = len(pairs)\n",
    "  input_ids = np.zeros((n,MAX_LEN), dtype=np.int32)\n",
    "  target_ids = np.zeros((n,MAX_LEN), dtype=np.int32)\n",
    "\n",
    "  for idx, (inp, tgt) in enumerate(pairs):\n",
    "    inp_ids = indexesFromSentence(input_lang, inp)\n",
    "    tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "    inp_ids.append(EOS_token)\n",
    "    tgt_ids.append(EOS_token)\n",
    "    input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "    target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "  train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                             torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "  train_sampler = RandomSampler(train_data)\n",
    "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "  return input_lang, output_lang, train_dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qzWJIenDqjxl"
   },
   "outputs": [],
   "source": [
    "def train_epoch(data_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "\n",
    "  total_loss = 0\n",
    "  for data in data_loader:\n",
    "    input_tensor, target_tensor = data\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "    decoder_outputs,_,_ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "    loss = criterion(\n",
    "        decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "        target_tensor.view(-1)\n",
    "    )\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "  return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "psKLxkoBrk7a"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jK0ByxfUro09"
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, print_every=100, plot_every=100):\n",
    "  start = time.time()\n",
    "  plot_losses = []\n",
    "  print_loss_total = 0\n",
    "  plot_loss_total = 0\n",
    "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "  criterion = nn.NLLLoss()\n",
    "\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    print_loss_total += loss\n",
    "    if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KqIfxAqRtDD0"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "  with torch.no_grad():\n",
    "    input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "\n",
    "    decoder_outputs, decoder_hidden, decoder_attention = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "    _, topi = decoder_outputs.topk(1)\n",
    "\n",
    "    decoded_ids = topi.squeeze()\n",
    "    decoded_words = []\n",
    "\n",
    "    for idx in decoded_ids:\n",
    "      if idx.item()==EOS_token:\n",
    "        decoded_words.append('<EOS>')\n",
    "        break\n",
    "      else:\n",
    "        decoded_words.append(output_lang.index2word[idx.item()])\n",
    "  return decoded_words, decoder_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "c-lGmv_MuMZ1"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-aGa-bUbuNCk",
    "outputId": "137a29c1-11da-4e2c-c912-3454070f6092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Lines......\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words....\n",
      "Counted Words\n",
      "fra 4601\n",
      "eng 2991\n",
      "0m 36s (- 9m 6s) (5 6%) 1.5576\n",
      "1m 11s (- 8m 21s) (10 12%) 0.6975\n",
      "1m 49s (- 7m 56s) (15 18%) 0.3649\n",
      "2m 28s (- 7m 24s) (20 25%) 0.2033\n",
      "3m 3s (- 6m 42s) (25 31%) 0.1255\n",
      "3m 38s (- 6m 3s) (30 37%) 0.0869\n",
      "4m 13s (- 5m 25s) (35 43%) 0.0657\n",
      "4m 47s (- 4m 47s) (40 50%) 0.0530\n",
      "5m 21s (- 4m 10s) (45 56%) 0.0460\n",
      "5m 56s (- 3m 33s) (50 62%) 0.0410\n",
      "6m 30s (- 2m 57s) (55 68%) 0.0376\n",
      "7m 4s (- 2m 21s) (60 75%) 0.0349\n",
      "7m 39s (- 1m 45s) (65 81%) 0.0333\n",
      "8m 13s (- 1m 10s) (70 87%) 0.0315\n",
      "8m 48s (- 0m 35s) (75 93%) 0.0304\n",
      "9m 22s (- 0m 0s) (80 100%) 0.0295\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vlAdbK42uTw7",
    "outputId": "a84bdde0-11eb-4ecc-9253-2dec5bc9720c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> votre decollage est confirme\n",
      "= you are cleared for takeoff\n",
      "< you are cleared for takeoff <EOS>\n",
      "\n",
      "> elle rassemble du materiel pour un livre\n",
      "= she is collecting material for a book\n",
      "< she is collecting material for a book <EOS>\n",
      "\n",
      "> je suis assez grand pour boire un coup\n",
      "= i m old enough to drink\n",
      "< i m old enough to drink <EOS>\n",
      "\n",
      "> je ne suis pas sur d aimer ca\n",
      "= i m not sure i like this\n",
      "< i m not sure i like this <EOS>\n",
      "\n",
      "> c est un homme de foi\n",
      "= he is a man of faith\n",
      "< he is a man of faith <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfIUSVVenO-8",
    "outputId": "591b5d00-19e4-4722-c22c-be70c4128c2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9mxqAqKnCxO",
    "outputId": "2eea84fa-8e8e-445f-aa39-4a934e7d208b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.28764198060873264\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def calculate_bleu(reference, candidate):\n",
    "    reference = [word_tokenize(sentence.lower()) for sentence in reference]\n",
    "    candidate = word_tokenize(candidate.lower())\n",
    "\n",
    "    smoothing_function = SmoothingFunction().method1  # You can choose different smoothing methods\n",
    "\n",
    "    return sentence_bleu(reference, candidate, smoothing_function=smoothing_function)\n",
    "\n",
    "# Example usage:\n",
    "reference_sentence = [\"The cat is sitting on the mat\"]\n",
    "candidate_sentence = \"The cat is on the mat\"\n",
    "\n",
    "bleu_score = calculate_bleu(reference_sentence, candidate_sentence)\n",
    "print(f\"BLEU Score: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vkye2saGnMfE"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def bleu_metric(encoder, decoder, n=10):\n",
    "    bleu=0\n",
    "    for i in tqdm(range(n)):\n",
    "        pair = random.choice(pairs)\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        reference_sentence = [pair[1]]\n",
    "        candidate_sentence = output_sentence\n",
    "        bleu+= calculate_bleu(reference_sentence, candidate_sentence)\n",
    "    return bleu/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6wkUVAvnOEN",
    "outputId": "60ad574d-9337-4eca-fa25-73fa83882475"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:11<00:00, 140.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42371017698449914"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric(encoder, decoder, n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_5a7iVmnZLw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
